{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Y51HMAtCt5cS"},"outputs":[],"source":["\n","!pip -q install -U \"huggingface_hub<1.0,>=0.34.0\" accelerate safetensors opencv-python\n","!pip -q install -U diffusers transformers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D_5-yuyIt5Wp"},"outputs":[],"source":["\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","%cd \"/content/drive/Othercomputers/ה-Mac שלי/StormVision\"\n","!pwd\n","!ls\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B7qImL82t5Vz"},"outputs":[],"source":["\n","import os, json, random\n","from pathlib import Path\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import torch\n","from PIL import Image, ImageDraw, ImageFilter, ImageEnhance\n","from tqdm.auto import tqdm\n","import matplotlib.pyplot as plt\n","\n","from huggingface_hub import login\n","from diffusers import ControlNetModel, StableDiffusionControlNetInpaintPipeline, DPMSolverMultistepScheduler\n","\n","RANDOM_SEED = 42\n","random.seed(RANDOM_SEED)\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","dtype = torch.float16 if device == \"cuda\" else torch.float32\n","print(\"device:\", device, \"| torch:\", torch.__version__)\n","\n","BASE_DIR = Path.cwd()\n","DATA_DIR = BASE_DIR / \"data\"\n","\n","IMG_TRAIN_DIR = DATA_DIR / \"images\" / \"train\"\n","IMG_VAL_DIR   = DATA_DIR / \"images\" / \"val\"\n","ANN_DIR       = DATA_DIR / \"annotations\"\n","\n","TRAIN_JSON    = ANN_DIR / \"instances_train.json\"\n","VAL_JSON      = ANN_DIR / \"instances_val.json\"\n","\n","assert IMG_TRAIN_DIR.exists(), f\"Missing: {IMG_TRAIN_DIR}\"\n","assert IMG_VAL_DIR.exists(),   f\"Missing: {IMG_VAL_DIR}\"\n","assert TRAIN_JSON.exists(),    f\"Missing: {TRAIN_JSON}\"\n","assert VAL_JSON.exists(),      f\"Missing: {VAL_JSON}\"\n","\n","# Output: ONE folder only\n","OUT_DIR = BASE_DIR / \"storm_synth_out_onefolder\"\n","OUT_IMAGES_DIR = OUT_DIR / \"images\"\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","OUT_IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n","print(\"OK. Output:\", OUT_DIR)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jCPXBryt5QM"},"outputs":[],"source":["\n","tok = os.environ.get(\"HF_TOKEN\", None)\n","if tok:\n","    login(token=tok)\n","else:\n","    login()"]},{"cell_type":"markdown","metadata":{"id":"Rkd4bDJJcZLJ"},"source":["##  Load COCO + build image-level dataframe (train/val pool)\n","- Loads COCO JSONs, infers person category IDs, builds image-level metadata (bboxes/counts), and merges train+val into one pool for generation.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XcKjr7lvt5PX"},"outputs":[],"source":["#  Load a COCO JSON file and return the raw dict plus images/annotations/categories as DataFrames.\n","def load_coco(json_path: Path):\n","    with open(json_path, \"r\") as f:\n","        coco = json.load(f)\n","    images_df = pd.DataFrame(coco.get(\"images\", []))         # COCO images table\n","    ann_df    = pd.DataFrame(coco.get(\"annotations\", []))    # COCO annotations table\n","    cats_df   = pd.DataFrame(coco.get(\"categories\", []))     # COCO categories table\n","    return coco, images_df, ann_df, cats_df\n","\n","#  Infer the category IDs that correspond to \"person-like\" classes from the COCO categories table.\n","def infer_person_category_ids(cats_df: pd.DataFrame, target_names=(\"person\",\"swimmer\",\"human\")):\n","    if cats_df is None or cats_df.empty:\n","        return set()\n","    if not {\"id\",\"name\"}.issubset(cats_df.columns):\n","        return set()\n","    names = cats_df[\"name\"].astype(str).str.lower()\n","    hits = cats_df[names.isin(set(target_names))]\n","    if not hits.empty:\n","        return set(hits[\"id\"].astype(int).tolist())\n","    hits2 = cats_df[names.str.contains(\"person|human|swim\", regex=True, na=False)] # exact match first\n","    return set(hits2[\"id\"].astype(int).tolist())\n","\n","#  Build an image-level DataFrame with per-image bbox lists and person presence/count signals.\n","def build_image_level_df(images_df: pd.DataFrame, ann_df: pd.DataFrame, person_cat_ids: set):\n","    images_df = images_df.copy()\n","    if ann_df.empty:\n","        ann_df = pd.DataFrame(columns=[\"image_id\",\"category_id\",\"bbox\"])\n","\n","    if {\"image_id\",\"category_id\",\"bbox\"}.issubset(ann_df.columns) and len(person_cat_ids) > 0:\n","        person_ann = ann_df[ann_df[\"category_id\"].isin(person_cat_ids)].copy()\n","    else:\n","        person_ann = pd.DataFrame(columns=[\"image_id\",\"category_id\",\"bbox\"])\n","\n","    boxes_per_image = (\n","        person_ann.groupby(\"image_id\")[\"bbox\"]\n","        .apply(list).reset_index().rename(columns={\"bbox\":\"bboxes\"})\n","    )\n","\n","    df = images_df.merge(boxes_per_image, left_on=\"id\", right_on=\"image_id\", how=\"left\")\n","    df[\"bboxes\"] = df[\"bboxes\"].apply(lambda x: x if isinstance(x, list) else [])\n","    df[\"has_person\"] = (df[\"bboxes\"].apply(len) > 0).astype(int)\n","    df[\"persons_count\"] = df[\"bboxes\"].apply(len)\n","    df[\"aspect_ratio\"] = df[\"width\"] / df[\"height\"]\n","    df = df.drop(columns=[\"image_id\"], errors=\"ignore\")\n","    return df[[\"id\",\"file_name\",\"width\",\"height\",\"has_person\",\"persons_count\",\"bboxes\",\"aspect_ratio\"]]\n","\n","coco_tr, img_tr_df, ann_tr_df, cats_tr_df = load_coco(TRAIN_JSON)\n","coco_va, img_va_df, ann_va_df, cats_va_df = load_coco(VAL_JSON)\n","\n","person_ids_tr = infer_person_category_ids(cats_tr_df)\n","person_ids_va = infer_person_category_ids(cats_va_df)\n","assert len(person_ids_tr) > 0 and len(person_ids_va) > 0, \"Could not infer person category ids\"\n","\n","train_image_df = build_image_level_df(img_tr_df, ann_tr_df, person_ids_tr)\n","val_image_df   = build_image_level_df(img_va_df, ann_va_df, person_ids_va)\n","\n","print(\"train:\", train_image_df.shape, \"pos%:\", round(train_image_df[\"has_person\"].mean()*100, 2))\n","print(\"val:\",   val_image_df.shape,   \"pos%:\", round(val_image_df[\"has_person\"].mean()*100, 2))\n","\n","# Keep only person categories (from TRAIN for consistency)\n","person_cats_tr = cats_tr_df[cats_tr_df[\"id\"].isin(list(person_ids_tr))].copy()\n","person_cats_tr = person_cats_tr[[\"id\",\"name\"]].to_dict(orient=\"records\")\n","PERSON_CAT_ID  = int(person_cats_tr[0][\"id\"])\n","\n","# Merge train+val into one pool (no split in output)\n","train_pool = train_image_df.copy()\n","train_pool[\"src_split\"] = \"train\"\n","train_pool[\"src_dir\"] = str(IMG_TRAIN_DIR)\n","\n","val_pool = val_image_df.copy()\n","val_pool[\"src_split\"] = \"val\"\n","val_pool[\"src_dir\"] = str(IMG_VAL_DIR)\n","\n","full_pool = pd.concat([train_pool, val_pool], ignore_index=True)\n","print(\"full_pool:\", full_pool.shape, \"pos%:\", round(full_pool[\"has_person\"].mean()*100, 2))\n"]},{"cell_type":"markdown","metadata":{"id":"B_caTwdxcZLL"},"source":["##  Scenario prompts (weather/visibility conditions)\n","- Defines prompt templates, sampling weights, and a negative prompt to reduce layout changes and artifacts.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uEyQJGh4t5KC"},"outputs":[],"source":["\n","\n","PROMPT_PREFIX = (\n","    \"aerial drone photo over the sea, same camera angle, same composition, \"\n","    \"preserve existing boats/buoys/people positions and sizes, realistic\"\n",")\n","\n","SCENARIOS = {\n","    \"haze\": [\n","        f\"{PROMPT_PREFIX}, heavy haze, reduced contrast, washed-out colors, distant horizon barely visible\",\n","    ],\n","    \"fog\": [\n","        f\"{PROMPT_PREFIX}, dense sea fog layer, very low visibility, soft diffuse light, muted colors\",\n","        f\"{PROMPT_PREFIX}, patchy fog banks, uneven visibility, some areas clearer, some obscured\",\n","    ],\n","    \"poor_visibility\": [\n","        f\"{PROMPT_PREFIX}, strong atmospheric scattering, low contrast, horizon fades, visibility strongly reduced\",\n","    ],\n","    \"storm_rain\": [\n","        f\"{PROMPT_PREFIX}, heavy rain storm, rain streaks, rain curtain, wind-driven spray, dark overcast sky\",\n","    ],\n","    \"wind_spray\": [\n","        f\"{PROMPT_PREFIX}, strong wind, sea spray, spindrift, streaked surface texture, overcast lighting\",\n","    ],\n","    \"high_sea_state\": [\n","        f\"{PROMPT_PREFIX}, rough sea, higher waves, whitecaps, foam lines, choppy surface\",\n","    ],\n","    \"extreme_waves\": [\n","        f\"{PROMPT_PREFIX}, extremely rough sea, large swell, chaotic waves, lots of whitecaps, heavy foam patterns\",\n","    ],\n","    \"whiteout_mix\": [\n","        f\"{PROMPT_PREFIX}, rain plus fog mix, extremely low visibility but objects still faintly visible, soft edges\",\n","    ],\n","    \"low_light_storm\": [\n","        f\"{PROMPT_PREFIX}, low-light storm, dim ambient light, bluish-gray tone, low saturation, heavy clouds\",\n","    ],\n","}\n","\n","SCENARIO_WEIGHTS = {\n","    \"haze\": 1.2,\n","    \"fog\": 1.2,\n","    \"poor_visibility\": 1.2,\n","    \"storm_rain\": 1.3,\n","    \"wind_spray\": 1.1,\n","    \"high_sea_state\": 1.2,\n","    \"extreme_waves\": 1.2,\n","    \"whiteout_mix\": 0.6,\n","    \"low_light_storm\": 0.8,\n","}\n","\n","NEG_PROMPT = (\n","    \"object removal, missing boats, missing people, extra boats, extra people, new large objects, hallucinated ships, \"\n","    \"changed composition, changed camera angle, crop, zoom, perspective change, \"\n","    \"text, watermark, logo, UI elements, black squares, checkerboard, artifacts, \"\n","    \"cartoon, illustration, CGI, lowres, blurry, deformed\"\n",")\n","\n","#  Randomly sample a scenario (weighted) and return its name plus a matching text prompt.\n","def sample_scenario_and_prompt(rng: random.Random):\n","    keys = list(SCENARIOS.keys())\n","    weights = [SCENARIO_WEIGHTS.get(k, 1.0) for k in keys]\n","    scenario = rng.choices(keys, weights=weights, k=1)[0]\n","    prompt = rng.choice(SCENARIOS[scenario])\n","    return scenario, prompt\n"]},{"cell_type":"markdown","metadata":{"id":"1mEBUGGKcZLM"},"source":["##  Inpainting masks + ControlNet conditioning (Canny)\n","- Builds masks that protect people and edges while allowing controlled edits in sky/sea bands.\n","- Builds a Canny edge image used as ControlNet input.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTVHmielt5AP"},"outputs":[],"source":["#  Detect a large mostly-black rectangular region to protect it from inpainting.\n","def detect_large_black_boxes(img_rgb: Image.Image, thr=18, min_area=1500):\n","    arr = np.array(img_rgb)\n","    black = (arr[...,0] < thr) & (arr[...,1] < thr) & (arr[...,2] < thr)\n","    ys, xs = np.where(black)\n","    if len(xs) == 0:\n","        return None\n","    x0, x1 = xs.min(), xs.max()\n","    y0, y1 = ys.min(), ys.max()\n","    if (x1 - x0) * (y1 - y0) < min_area:\n","        return None\n","    return (int(x0), int(y0), int(x1), int(y1))\n","\n","\n","#  Create an inpaint mask that repaints sky and optionally sea while protecting persons and edges.\n","def build_weather_inpaint_mask(\n","    img_rgb: Image.Image,\n","    bboxes,\n","    scenario: str,\n","    keep_pad=140,\n","    sky_frac=0.32,\n","    sea_from_frac=0.55,\n","    keep_edges=True,\n","    edge_canny1=140,\n","    edge_canny2=260,\n","    edge_dilate=5,\n","    keep_black_boxes=True,\n","):\n","    \"\"\"\n","    Returns mask L:\n","    white (255) = repaint (inpaint)\n","    black (0)   = keep from original\n","\n","    Strategy:\n","    - repaint mainly SKY band always (minimal structure changes)\n","    - for wave scenarios, also repaint SEA lower band\n","    - always protect persons via bbox rectangles (black)\n","    - optionally protect edges globally (black where edges exist)\n","    \"\"\"\n","    W, H = img_rgb.size\n","    mask = Image.new(\"L\", (W, H), 0)\n","    mask_np = np.array(mask)\n","\n","    # 1) Allow repaint on sky band\n","    y_sky = int(np.clip(sky_frac, 0.05, 0.60) * H)\n","    mask_np[0:y_sky, :] = 255\n","\n","    # 2) Allow repaint on sea band only for wave-related scenarios\n","    if scenario in [\"high_sea_state\", \"extreme_waves\", \"wind_spray\", \"storm_rain\", \"poor_visibility\", \"fog\"]:\n","        y0 = int(np.clip(sea_from_frac, 0.30, 0.90) * H)\n","        mask_np[y0:H, :] = 255\n","\n","    # 3) Protect objects (persons) with padding\n","    for (x, y, w, h) in bboxes:\n","        x0 = max(0, int(x - keep_pad)); y0 = max(0, int(y - keep_pad))\n","        x1 = min(W, int(x + w + keep_pad)); y1 = min(H, int(y + h + keep_pad))\n","        mask_np[y0:y1, x0:x1] = 0\n","\n","    # 4) Protect global edges to keep geometry stable\n","    if keep_edges:\n","        arr = np.array(img_rgb)\n","        gray = cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)\n","        edges = cv2.Canny(gray, edge_canny1, edge_canny2)\n","        k = edge_dilate if edge_dilate % 2 == 1 else edge_dilate + 1\n","        kernel = np.ones((k, k), np.uint8)\n","        edges = cv2.dilate(edges, kernel, iterations=1)\n","        mask_np[edges > 0] = 0\n","\n","    # 5) Protect black boxes if exist\n","    if keep_black_boxes:\n","        bb = detect_large_black_boxes(img_rgb)\n","        if bb:\n","            x0,y0,x1,y1 = bb\n","            mask_np[y0:y1, x0:x1] = 0\n","\n","    return Image.fromarray(mask_np.astype(np.uint8), mode=\"L\")\n","\n","\n","#  Build a 3-channel Canny edge image to use as the ControlNet conditioning input.\n","def build_canny_control_image(img_rgb: Image.Image, canny1=100, canny2=200):\n","    arr = np.array(img_rgb)\n","    gray = cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)\n","    edges = cv2.Canny(gray, canny1, canny2)\n","    edges_3 = np.stack([edges, edges, edges], axis=-1)\n","    return Image.fromarray(edges_3)"]},{"cell_type":"markdown","metadata":{"id":"GTe6zCWwcZLM"},"source":["##  post-processing overlays (fog/rain/low light)\n","- Adds lightweight visual effects after generation to strengthen the target weather condition without changing geometry.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZK6TWYmSt41n"},"outputs":[],"source":["#  Apply a simple haze/fog look by blending a tinted overlay and reducing contrast/saturation.\n","def add_fog_haze(img: Image.Image, strength=0.35, tint=(200, 200, 200)):\n","    overlay = Image.new(\"RGB\", img.size, tint)\n","    out = Image.blend(img, overlay, alpha=float(np.clip(strength, 0, 0.85)))\n","    out = ImageEnhance.Contrast(out).enhance(1.0 - 0.25*strength)\n","    out = ImageEnhance.Color(out).enhance(1.0 - 0.30*strength)\n","    return out\n","\n","#  Add synthetic rain streaks using random slanted line drawing and compositing.\n","def add_rain_streaks(img: Image.Image, amount=0.35, thickness=1, slant=12):\n","    arr = np.array(img).astype(np.uint8)\n","    h, w = arr.shape[:2]\n","    rain = np.zeros((h, w), dtype=np.uint8)\n","\n","    n = int((h*w) * (0.00006 + 0.00025*amount))\n","    rng = np.random.default_rng(1234)\n","    xs = rng.integers(0, w, size=n)\n","    ys = rng.integers(0, h, size=n)\n","    for x, y in zip(xs, ys):\n","        x2 = int(x + slant)\n","        y2 = int(y + 22 + 40*amount)\n","        cv2.line(rain, (x, y), (x2, y2), 255, thickness=thickness)\n","\n","    rain = cv2.GaussianBlur(rain, (3,3), 0)\n","    rain_rgb = np.stack([rain, rain, rain], axis=-1)\n","\n","    out = cv2.addWeighted(arr, 1.0, rain_rgb, 0.22 + 0.35*amount, 0)\n","    return Image.fromarray(out)\n","\n","#  Darken and desaturate an image to simulate low-light storm conditions.\n","def add_low_light(img: Image.Image, amount=0.35):\n","    out = ImageEnhance.Brightness(img).enhance(1.0 - 0.55*amount)\n","    out = ImageEnhance.Color(out).enhance(1.0 - 0.45*amount)\n","    return out\n","\n","#  Apply a scenario-specific post overlay (fog/rain/low-light) to strengthen the weather effect.\n","def apply_weather_overlay(img: Image.Image, scenario: str):\n","    if scenario in [\"haze\"]:\n","        img = add_fog_haze(img, strength=0.40, tint=(205,205,205))\n","    elif scenario in [\"fog\", \"poor_visibility\"]:\n","        img = add_fog_haze(img, strength=0.55, tint=(210,210,210))\n","        img = img.filter(ImageFilter.GaussianBlur(radius=0.8))\n","    elif scenario in [\"whiteout_mix\"]:\n","        img = add_fog_haze(img, strength=0.70, tint=(220,220,220))\n","        img = add_rain_streaks(img, amount=0.55, thickness=1, slant=8)\n","        img = img.filter(ImageFilter.GaussianBlur(radius=1.1))\n","    elif scenario in [\"storm_rain\"]:\n","        img = add_rain_streaks(img, amount=0.55, thickness=1, slant=10)\n","        img = add_fog_haze(img, strength=0.25, tint=(190,190,190))\n","    elif scenario in [\"wind_spray\"]:\n","        img = add_fog_haze(img, strength=0.28, tint=(200,200,200))\n","    elif scenario in [\"low_light_storm\"]:\n","        img = add_low_light(img, amount=0.55)\n","        img = add_fog_haze(img, strength=0.25, tint=(180,180,190))\n","    elif scenario in [\"high_sea_state\", \"extreme_waves\"]:\n","        img = add_fog_haze(img, strength=0.18, tint=(195,195,195))\n","    return img\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aqXtqiS0cZLN"},"source":["## Load Stable Diffusion Inpainting + ControlNet (Canny)\n","- Loads the inpainting model and matching ControlNet, configures scheduler and memory optimizations.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SuzGnPj_v-ru"},"outputs":[],"source":["\n","MODEL_INPAINT_ID    = \"runwayml/stable-diffusion-inpainting\"\n","CONTROLNET_CANNY_ID = \"lllyasviel/control_v11p_sd15_canny\"\n","\n","controlnet = ControlNetModel.from_pretrained(CONTROLNET_CANNY_ID, torch_dtype=dtype)\n","\n","pipe = StableDiffusionControlNetInpaintPipeline.from_pretrained(\n","    MODEL_INPAINT_ID,\n","    controlnet=controlnet,\n","    torch_dtype=dtype,\n","    safety_checker=None,\n","    requires_safety_checker=False,\n",").to(device)\n","\n","pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n","pipe.enable_attention_slicing()\n","pipe.enable_vae_slicing()\n","print(\"Pipes loaded.\")"]},{"cell_type":"markdown","metadata":{"id":"4QeG9KLtcZLN"},"source":["## Core generation function (ControlNet Inpaint + optional overlay)\n","- Generates one synthetic image per input using: sampled scenario prompt + inpaint mask + Canny control image.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_LfWdy4wPkW"},"outputs":[],"source":["\n","#  Generate a single weather-augmented image using ControlNet inpainting while preserving people via masks.\n","@torch.inference_mode()\n","def gen_controlnet_weather(\n","    img_path: Path,\n","    bboxes,\n","    seed: int,\n","    max_side=768,\n","    steps=26,\n","    guidance_scale=4.0,\n","    controlnet_scale=1.10,\n","    keep_pad=160,\n","    sky_frac=0.32,\n","    sea_from_frac=0.60,\n","    keep_edges=True,\n","    edge_dilate=5,\n","    apply_overlay=True,\n","):\n","    img = Image.open(img_path).convert(\"RGB\")\n","    img_small, orig_size, (sx, sy) = resize_to_max_side(img, max_side=max_side)\n","    b_scaled = scale_bboxes(bboxes, sx, sy)\n","\n","    rng = random.Random(seed)\n","    scenario, prompt = sample_scenario_and_prompt(rng)\n","\n","    mask = build_weather_inpaint_mask(\n","        img_small,\n","        b_scaled,\n","        scenario=scenario,\n","        keep_pad=keep_pad,\n","        sky_frac=sky_frac,\n","        sea_from_frac=sea_from_frac,\n","        keep_edges=keep_edges,\n","        edge_dilate=edge_dilate,\n","        keep_black_boxes=True,\n","    )\n","\n","    control_image = build_canny_control_image(img_small, canny1=100, canny2=200)\n","    g = torch.Generator(device=device).manual_seed(seed)\n","\n","    out = pipe(\n","        prompt=prompt,\n","        negative_prompt=NEG_PROMPT,\n","        image=img_small,\n","        mask_image=mask,\n","        control_image=control_image,\n","        num_inference_steps=int(steps),\n","        guidance_scale=float(guidance_scale),\n","        controlnet_conditioning_scale=float(controlnet_scale),\n","        generator=g,\n","    ).images[0]\n","\n","    if apply_overlay:\n","        out = apply_weather_overlay(out, scenario)\n","\n","    return out, img_small, mask, control_image, b_scaled, scenario, prompt"]},{"cell_type":"markdown","metadata":{"id":"4d-26E7lcZLN"},"source":["## COCO writer + ONEFOLDER dataset generator\n","- Writes COCO structures for generated images and annotations.\n","- Generates positive and negative synthetic samples and logs a metadata CSV mapping original to synthetic.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cB0sKBSgwPjZ"},"outputs":[],"source":["\n","#  Initialize a COCO-format dict with person categories and empty images/annotations lists.\n","def coco_init(person_categories):\n","    return {\"info\": {}, \"licenses\": [], \"images\": [], \"annotations\": [], \"categories\": person_categories}\n","\n","#  Append an image record to the COCO dict.\n","def add_coco_image(coco, img_id, file_name, width, height):\n","    coco[\"images\"].append({\"id\": int(img_id), \"file_name\": str(file_name), \"width\": int(width), \"height\": int(height)})\n","\n","#  Append a bbox annotation record to the COCO dict.\n","def add_coco_ann(coco, ann_id, img_id, cat_id, bbox):\n","    x,y,w,h = bbox\n","    area = float(max(0.0, w) * max(0.0, h))\n","    coco[\"annotations\"].append({\n","        \"id\": int(ann_id),\n","        \"image_id\": int(img_id),\n","        \"category_id\": int(cat_id),\n","        \"bbox\": [float(x), float(y), float(w), float(h)],\n","        \"area\": area,\n","        \"iscrowd\": 0\n","    })\n","\n","#  Sample positives/negatives, generate synthetic images, and return COCO annotations plus a metadata DataFrame.\n","def generate_onefolder(\n","    pool_df: pd.DataFrame,\n","    out_images_dir: Path,\n","    n_pos=200,\n","    n_neg=200,\n","    start_seed=3000,\n","    max_side=768,\n","    steps=26,\n","    guidance_scale=4.0,\n","    controlnet_scale=1.10,\n","    keep_pad=160,\n","    sky_frac=0.32,\n","    sea_from_frac=0.60,\n","    keep_edges=True,\n","    edge_dilate=5,\n","    apply_overlay=True,\n","):\n","    coco = coco_init(person_cats_tr)\n","    meta_rows = []\n","\n","    pos_df = pool_df[pool_df[\"has_person\"] == 1]\n","    neg_df = pool_df[pool_df[\"has_person\"] == 0]\n","\n","    pos_sample = pos_df.sample(min(n_pos, len(pos_df)), random_state=RANDOM_SEED).reset_index(drop=True)\n","    neg_sample = neg_df.sample(min(n_neg, len(neg_df)), random_state=RANDOM_SEED).reset_index(drop=True)\n","\n","    next_img_id = 1\n","    next_ann_id = 1\n","\n","    # POS\n","    for i, r in tqdm(list(enumerate(pos_sample.itertuples(index=False), start=1)), desc=\"ONEFOLDER POS\"):\n","        src_dir = Path(r.src_dir)\n","        img_path = src_dir / r.file_name\n","\n","        out, inp, mask, canny_img, b_scaled, scenario, prompt = gen_controlnet_weather(\n","            img_path=img_path,\n","            bboxes=r.bboxes,\n","            seed=start_seed + i,\n","            max_side=max_side,\n","            steps=steps,\n","            guidance_scale=guidance_scale,\n","            controlnet_scale=controlnet_scale,\n","            keep_pad=keep_pad,\n","            sky_frac=sky_frac,\n","            sea_from_frac=sea_from_frac,\n","            keep_edges=keep_edges,\n","            edge_dilate=edge_dilate,\n","            apply_overlay=apply_overlay,\n","        )\n","\n","        out_name = f\"synth_pos_{r.id}_{i}.jpg\"\n","        out.save(out_images_dir / out_name, quality=95)\n","\n","        W, H = out.size\n","        add_coco_image(coco, next_img_id, out_name, W, H)\n","        for bb in b_scaled:\n","            add_coco_ann(coco, next_ann_id, next_img_id, PERSON_CAT_ID, bb)\n","            next_ann_id += 1\n","\n","        meta_rows.append({\n","            \"label\": 1,\n","            \"src_split\": r.src_split,\n","            \"orig_file\": r.file_name,\n","            \"out_file\": out_name,\n","            \"scenario\": scenario,\n","            \"prompt\": prompt\n","        })\n","        next_img_id += 1\n","\n","    # NEG\n","    for i, r in tqdm(list(enumerate(neg_sample.itertuples(index=False), start=1)), desc=\"ONEFOLDER NEG\"):\n","        src_dir = Path(r.src_dir)\n","        img_path = src_dir / r.file_name\n","\n","        out, inp, mask, canny_img, b_scaled, scenario, prompt = gen_controlnet_weather(\n","            img_path=img_path,\n","            bboxes=[],\n","            seed=start_seed + 5000 + i,\n","            max_side=max_side,\n","            steps=steps,\n","            guidance_scale=guidance_scale,\n","            controlnet_scale=controlnet_scale,\n","            keep_pad=keep_pad,\n","            sky_frac=sky_frac,\n","            sea_from_frac=sea_from_frac,\n","            keep_edges=keep_edges,\n","            edge_dilate=edge_dilate,\n","            apply_overlay=apply_overlay,\n","        )\n","\n","        out_name = f\"synth_neg_{r.id}_{i}.jpg\"\n","        out.save(out_images_dir / out_name, quality=95)\n","\n","        W, H = out.size\n","        add_coco_image(coco, next_img_id, out_name, W, H)\n","\n","        meta_rows.append({\n","            \"label\": 0,\n","            \"src_split\": r.src_split,\n","            \"orig_file\": r.file_name,\n","            \"out_file\": out_name,\n","            \"scenario\": scenario,\n","            \"prompt\": prompt\n","        })\n","        next_img_id += 1\n","\n","    meta_df = pd.DataFrame(meta_rows)\n","    return coco, meta_df\n","\n","\n","# Run configuration + dataset generation + saving outputs\n","# Sets generation hyperparameters, runs synthesis, and saves COCO JSON + metadata CSV to the output folder.\n","\n","\n","\n","CFG = {\n","    \"max_side\": 768,\n","    \"steps\": 35,\n","    \"guidance_scale\": 7.5,\n","    \"controlnet_scale\": 0.85,\n","    \"keep_pad\": 220,\n","    \"sky_frac\": 0.48,\n","    \"sea_from_frac\": 0.45,\n","    \"keep_edges\": True,\n","    \"edge_dilate\": 3,\n","    \"apply_overlay\": True,\n","}\n","\n","\n","N_POS = 150\n","N_NEG = 150\n","\n","print(\"=== Generating ONEFOLDER dataset ===\")\n","coco_synth, meta_synth = generate_onefolder(\n","    pool_df=full_pool,\n","    out_images_dir=OUT_IMAGES_DIR,\n","    n_pos=N_POS,\n","    n_neg=N_NEG,\n","    start_seed=3000,\n","    max_side=CFG[\"max_side\"],\n","    steps=CFG[\"steps\"],\n","    guidance_scale=CFG[\"guidance_scale\"],\n","    controlnet_scale=CFG[\"controlnet_scale\"],\n","    keep_pad=CFG[\"keep_pad\"],\n","    sky_frac=CFG[\"sky_frac\"],\n","    sea_from_frac=CFG[\"sea_from_frac\"],\n","    keep_edges=CFG[\"keep_edges\"],\n","    edge_dilate=CFG[\"edge_dilate\"],\n","    apply_overlay=CFG[\"apply_overlay\"],\n",")\n","\n","# Save outputs\n","OUT_JSON = OUT_DIR / \"instances_synth.json\"\n","OUT_META = OUT_DIR / \"meta_synth.csv\"\n","\n","with open(OUT_JSON, \"w\") as f:\n","    json.dump(coco_synth, f)\n","\n","meta_synth.to_csv(OUT_META, index=False)\n","\n","print(\"DONE.\")\n","print(\"Images folder:\", OUT_IMAGES_DIR)\n","print(\"COCO json:\", OUT_JSON)\n","print(\"Meta csv:\", OUT_META)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JyxuVzzWcZLO"},"source":["## Quick qualitative sanity check\n","- Randomly previews a few generated images to verify outputs visually.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3XxF7ZCOwOxE"},"outputs":[],"source":["# -------------------------\n","#  Quick preview (random 6)\n","# -------------------------\n","import glob\n","all_imgs = sorted(glob.glob(str(OUT_IMAGES_DIR / \"*.jpg\")))\n","print(\"generated:\", len(all_imgs))\n","\n","if len(all_imgs) > 0:\n","    sample = random.sample(all_imgs, k=min(6, len(all_imgs)))\n","    for p in sample:\n","        show(Image.open(p).convert(\"RGB\"), title=Path(p).name)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}